{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tutorial Credit\n",
    "[BeuatifulSoup Tutorial - Zillow Web Scraping in Python](https://www.youtube.com/watch?v=dRcvJRmqFHQ&t=68s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\\\n",
    "get bed and bath data\\\n",
    "possibly add in the floorplan values that are missing as NAN, more data = more better\\\n",
    "parse out special characters from csv, if a number is 250k turn the number into 250000\\\n",
    "\\\n",
    "ADD MORE LOCATION PARAMETERS, MORE DATA IS MORE BETTER, this will help with machine learning, long and lat will be help differentiate the price of a house in a specific area even if the model does't explicitely know what that area is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from GrossText import KCHeader\n",
    "from GrossText import OmahaHeader\n",
    "from GrossText import StJoeHeader\n",
    "#from GrossText import KCParams\n",
    "import time\n",
    "import csv\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZillowScraper():\n",
    "    results = []\n",
    "\n",
    "    def fetch(self, inurl, inparams, inHeader):\n",
    "        response = requests.get(url=inurl, headers=inHeader, params=inparams)\n",
    "        print(response.status_code)\n",
    "        return response\n",
    "    \n",
    "    def parse(self, response):\n",
    "        content = BeautifulSoup(response, 'lxml')\n",
    "        deck = content.find('ul',{'class':'List-c11n-8-100-4__sc-1smrmqp-0 StyledSearchListWrapper-srp-8-100-4__sc-1ieen0c-0 cRHZNY KKlAT photo-cards photo-cards_extra-attribution'})\n",
    "        for card in deck.contents:\n",
    "            script = card.find('script',{'type': 'application/ld+json'})\n",
    "            if script:\n",
    "                script_json = json.loads(script.contents[0])\n",
    "                    \n",
    "                if 'floorSize' in script_json and 'value' in script_json['floorSize']:\n",
    "                    #print(card.find('span', {'data-test': 'property-card-price', 'class': 'PropertyCardWrapper__StyledPriceLine-srp-8-100-4__sc-16e8gqd-1 dNnIRL'}).text)\n",
    "                    floor_size_value = script_json['floorSize']['value']\n",
    "                    if floor_size_value is not None:\n",
    "                        if re.search('[,]',floor_size_value):\n",
    "                            temp_floor_size_value = re.sub('[,]', '', floor_size_value)\n",
    "                            floor_size_value = temp_floor_size_value\n",
    "                        priceData = card.find('span', {'data-test': 'property-card-price', 'class': 'PropertyCardWrapper__StyledPriceLine-srp-8-100-4__sc-16e8gqd-1 dNnIRL'}).text\n",
    "                        if re.search('[Kk]',priceData):\n",
    "                            temp_priceData = re.sub('[Kk]', '000',priceData)\n",
    "                            priceData = temp_priceData\n",
    "                            continue\n",
    "                        elif re.search('[+,$]',priceData):\n",
    "                            temp_priceData = re.sub('[+,$]', '' , priceData)\n",
    "                            priceData = temp_priceData\n",
    "                            print(priceData)\n",
    "                        self.results.append({\n",
    "                            'latitude': script_json['geo']['latitude'],\n",
    "                            'longitude': script_json['geo']['longitude'],\n",
    "                            'floorSize': floor_size_value,\n",
    "                            #'bedrooms' : \n",
    "                            #'bathrooms' :\n",
    "                            'price': priceData,\n",
    "                            #'price': card.find('span', {'data-test': 'property-card-price', 'class': 'PropertyCardWrapper__StyledPriceLine-srp-8-100-4__sc-16e8gqd-1 dNnIRL'}).text,\n",
    "                            'url': script_json['url']\n",
    "                        })\n",
    "                else:\n",
    "                    print(\"shits empty\")\n",
    "                    print(script_json['url'])\n",
    "\n",
    "\n",
    "    def to_csv(self):\n",
    "        if not self.results:\n",
    "            print(\"No data to write to CSV.\")\n",
    "            return\n",
    "        \n",
    "        fieldnames = self.results[0].keys()  # Use keys from the first dictionary in results\n",
    "        with open('zillow.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "            writer = csv.DictWriter(csv_file, fieldnames=fieldnames, quoting=csv.QUOTE_ALL)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(self.results)  # Write all rows at once\n",
    "            \n",
    "    def run (self):\n",
    "        header1 = KCHeader\n",
    "        KCMOurl = \"https://www.zillow.com/homes/Kansas-City,-MO_rb/\"\n",
    "        #1,21\n",
    "        for page in range(1,21):\n",
    "            KCMOparams = {'searchQueryState': '{\"pagination\":{\"currentPage\": %s},\"isMapVisible\":false,\"mapBounds\":{\"west\":-95.01517262499999,\"east\":-94.13626637499999,\"south\":36.563341336709954,\"north\":41.533945017316555},\"usersSearchTerm\":\"Kansas City, MO\",\"regionSelection\":[{\"regionId\":18795,\"regionType\":6}],\"filterState\":{\"sort\":{\"value\":\"globalrelevanceex\"},\"ah\":{\"value\":true}},\"isListVisible\":true,\"mapZoom\":8}' %page}\n",
    "            KCMOres = self.fetch(KCMOurl, KCMOparams, header1)\n",
    "            self.parse(KCMOres.text)\n",
    "            randomNum = random.randint(30,60)\n",
    "            time.sleep(randomNum)\n",
    "    def run2 (self):\n",
    "        header2 = StJoeHeader\n",
    "        StJoeMOurl = \"https://www.zillow.com/homes/saint-joseph,-MO_rb/\"\n",
    "        #1,6\n",
    "        for page in range (1,6):\n",
    "            StJoeMOParams = {'searchQueryState': '{\"pagination\":{\"currentPage\": %s},\"isMapVisible\":true,\"mapBounds\":{\"west\":-95.1487722088861,\"east\":-94.52735802431579,\"south\":39.68412123060132,\"north\":39.754102210360905},\"regionSelection\":[{\"regionId\":40704,\"regionType\":6}],\"filterState\":{\"sort\":{\"value\":\"globalrelevanceex\"},\"ah\":{\"value\":true}},\"isEntirePlaceForRent\":true,\"isRoomForRent\":false,\"isListVisible\":true,\"mapZoom\":12}' %page}\n",
    "            StJoeMOres = self.fetch(StJoeMOurl, StJoeMOParams, header2)\n",
    "            self.parse(StJoeMOres.text)\n",
    "            randomNum = random.randint(30,60)\n",
    "            time.sleep(randomNum)\n",
    "    def run3 (self):\n",
    "        OmahaNEurl = \"https://www.zillow.com/homes/Omaha,-NE_rb/\"\n",
    "        header3 = OmahaHeader\n",
    "        #1,21\n",
    "        for page in range (1,21):\n",
    "            OmahaNeParams = {'searchQueryState': '{\"pagination\":{\"currentPage\": %s},\"isMapVisible\":true,\"mapBounds\":{\"west\":-96.7099553935547,\"east\":-95.46987360644532,\"south\":41.02791181891396,\"north\":41.527423622028884},\"usersSearchTerm\":\"Omaha, NE\",\"regionSelection\":[{\"regionId\":40152,\"regionType\":6}],\"filterState\":{\"sort\":{\"value\":\"globalrelevanceex\"},\"ah\":{\"value\":true}},\"isListVisible\":true}' %page}\n",
    "            OmahaNEres = self.fetch(OmahaNEurl, OmahaNeParams, header3)\n",
    "            self.parse(OmahaNEres.text)\n",
    "            randomNum = random.randint(21,34)\n",
    "            time.sleep(randomNum)\n",
    "    def run4 (self):\n",
    "        header4 = KCHeader\n",
    "        OverlandParkurl = 'https://www.zillow.com/homes/Overland-Park,-KS_rb/'\n",
    "        #1,7\n",
    "        for page in range (1,7):\n",
    "            OverlandPakrParams = {'searchQueryState': '{\"pagination\":{\"currentPage\": %s},\"isMapVisible\":false,\"mapBounds\":{\"west\":-94.68704246728515,\"east\":-94.24140953271484,\"south\":38.965938755457806,\"north\":39.62009235770738},\"mapZoom\":11,\"regionSelection\":[{\"regionId\":40202,\"regionType\":6}],\"filterState\":{\"sort\":{\"value\":\"globalrelevanceex\"},\"ah\":{\"value\":true}},\"isEntirePlaceForRent\":true,\"isRoomForRent\":false,\"isListVisible\":true}' %page}\n",
    "            OverlandPakrres = self.fetch(OverlandParkurl, OverlandPakrParams, header4)\n",
    "            self.parse(OverlandPakrres.text)\n",
    "            randomNum = random.randint(21,34)\n",
    "            time.sleep(randomNum)\n",
    "    def run5 (self):\n",
    "        header5 = KCHeader\n",
    "        KCKSurl = 'https://www.zillow.com/homes/Kansas-City,-KS_rb/'\n",
    "        #1,8\n",
    "        for page in range (1,8):\n",
    "            KCKSParams = {'searchQueryState': '{\"pagination\":{\"currentPage\": %s},\"isMapVisible\":true,\"mapBounds\":{\"west\":-95.67895551153367,\"east\":-93.89642377325242,\"south\":38.64494514451059,\"north\":39.63548678854779},\"mapZoom\":9,\"regionSelection\":[{\"regionId\":39191,\"regionType\":6}],\"filterState\":{\"sort\":{\"value\":\"globalrelevanceex\"},\"ah\":{\"value\":true}},\"isEntirePlaceForRent\":true,\"isRoomForRent\":false,\"isListVisible\":true}' %page}\n",
    "            KCKSres = self.fetch(KCKSurl, KCKSParams, header5)\n",
    "            self.parse(KCKSres.text)\n",
    "            randomNum = random.randint(21,34)\n",
    "            time.sleep(randomNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = ZillowScraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.run2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.run3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.run4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.run5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Vizualizaion time\n",
    "##### Hope it works\n",
    "plan is to make 2 graphs. first graph is a simple linear graph that plots price against square footage.\\\n",
    "Second graph is longitude and latitude for x,y and for each point I would like it to change color based on price and change size base on square footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to remove duplicates\n",
    "# dont need to run this again\n",
    "'''\n",
    "import csv\n",
    "\n",
    "def remove_duplicates(input_file, output_file):\n",
    "    # Initialize a set to keep track of seen rows\n",
    "    seen_rows = set()\n",
    "\n",
    "    # Open input and output CSV files\n",
    "    with open(input_file, 'r', newline='') as csv_input,  \\\n",
    "         open(output_file, 'w', newline='') as csv_output:\n",
    "\n",
    "        # Create CSV reader and writer objects\n",
    "        reader = csv.reader(csv_input)\n",
    "        writer = csv.writer(csv_output)\n",
    "\n",
    "        # Iterate through each row in the input CSV file\n",
    "        for row in reader:\n",
    "            # Convert the row to a tuple to make it hashable\n",
    "            row_tuple = tuple(row)\n",
    "            # Check if the row is not a duplicate\n",
    "            if row_tuple not in seen_rows:\n",
    "                # Write the non-duplicate row to the output CSV file\n",
    "                writer.writerow(row)\n",
    "                # Add the row to the set of seen rows\n",
    "                seen_rows.add(row_tuple)\n",
    "\n",
    "# Usage example:\n",
    "input_file = \"Zillow Scrape 4.10.24.csv\"\n",
    "output_file = 'output_unique.csv'\n",
    "remove_duplicates(input_file, output_file)\n",
    "print(f\"Unique data written to {output_file}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "file =  \"4.10.24 Duplicates Removed.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Extract the \"longitude\" and \"latitude\" columns\n",
    "longitude = df['longitude']\n",
    "latitude = df['latitude']\n",
    "\n",
    "# Plot longitude vs. latitude\n",
    "plt.figure(figsize=(8, 6))  # Set the figure size (width, height)\n",
    "\n",
    "plt.scatter(longitude, latitude, alpha=0.5)  # Plot the scatter plot\n",
    "plt.title('Scatter Plot of Longitude vs. Latitude')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "# Find the index of the row with the maximum floor size\n",
    "max_floor_size_index = df['floorSize'].idxmax()\n",
    "max_price_index = df['price'].idxmax()\n",
    "\n",
    "#getting ride of extreme outliers, they make the graph ugly\n",
    "df_modified = df.drop(index=max_floor_size_index)\n",
    "df_modified = df.drop(index=max_price_index)\n",
    "\n",
    "\n",
    "# Extract the \"price\" and \"floorSize\" columns from the modified DataFrame\n",
    "price = df_modified['price']\n",
    "floor_size = df_modified['floorSize']\n",
    "\n",
    "# Plot a scatter plot without the max floor size item\n",
    "plt.figure(figsize=(10, 6))  # Set the figure size (width, height)\n",
    "\n",
    "plt.scatter(floor_size, price, alpha=0.5)  # Plot the scatter plot\n",
    "plt.title('Scatter Plot of Price vs. Floor Size (Excluding Outliers)')\n",
    "plt.xlabel('Floor Size')\n",
    "plt.ylabel('Price')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Time\n",
    "\n",
    "going to try a bunch of different models to see if any is better than the other\n",
    "\n",
    "#### TODO:\n",
    "Poly Regression\\\n",
    "Kmeans\\\n",
    "Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial data reading, cleaning, and splitting\n",
    "cleanedFile = \"4.10.24 Duplicates Removed.csv\"\n",
    "DF = pd.read_csv(cleanedFile)\n",
    "\n",
    "DF.dropna(axis='index', how='any', inplace=True)\n",
    "\n",
    "train_set, test_set = train_test_split(DF, test_size=0.3, random_state=0)\n",
    "print(DF.keys)\n",
    "\n",
    "X = DF[['latitude', 'longitude', 'floorSize']]\n",
    "y = DF['price']\n",
    "\n",
    "X_train = train_set[['latitude', 'longitude', 'floorSize']]\n",
    "y_train = train_set['price']\n",
    "\n",
    "X_test = test_set[['latitude', 'longitude', 'floorSize']]\n",
    "y_test = test_set['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "LR = LinearRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = LR.predict(X_train)\n",
    "print(LR.score(X_train,y_train))\n",
    "print(mean_squared_error(y_train,y_predicted))\n",
    "print(sqrt(mean_squared_error(y_train,y_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "DTCWholeSet = DecisionTreeClassifier()\n",
    "DTCWholeSet.fit(X_train,y_train)\n",
    "\n",
    "DTC = DecisionTreeClassifier()\n",
    "DTC.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = DTC.predict(X_train)\n",
    "matrix = confusion_matrix(y_train,y_predicted)\n",
    "print(matrix)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Accuracy\", accuracy_score(y_train,y_predicted))\n",
    "print(\"Precision\", precision_score(y_train,y_predicted, average='weighted'))\n",
    "print(\"Sensitivity\", recall_score(y_train,y_predicted, average='weighted'))\n",
    "print(\"F1\", f1_score(y_train, y_predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Classic decision tree overfitting, I didn't give it any bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree 5 fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "spliter = StratifiedKFold(n_splits = 5, shuffle=True)\n",
    "\n",
    "\n",
    "for train_indices, validate_indices in spliter.split(X, y):\n",
    "    DTC = DecisionTreeClassifier()\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    DTC.fit(X_train,y_train)\n",
    "    X_validate = X.iloc[validate_indices]\n",
    "    y_validate = y.iloc[validate_indices]\n",
    "    y_predicted = DTC.predict(X_validate)\n",
    "    matrix = confusion_matrix(y_validate, y_predicted)\n",
    "    print(matrix)\n",
    "    print(\"Accuracy\", accuracy_score(y_validate,y_predicted))\n",
    "    print(\"F1\", f1_score(y_validate, y_predicted, average='weighted'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.svm import SVC\n",
    "SVM = SVC()\n",
    "\n",
    "\n",
    "SVM.fit(X_train, y_train)\n",
    "y_train_predict = SVM.predict(X_train)\n",
    "matrixTrain = confusion_matrix(y_train, y_train_predict)\n",
    "print(matrixTrain)\n",
    "print(\"Accuracy\", accuracy_score(y_train, y_train_predict))\n",
    "print(\"F1\", f1_score(y_train ,y_train_predict, average='weighted'))\n",
    "\n",
    "\n",
    "\n",
    "y_test_predict = SVM.predict(X_test)\n",
    "matrixTest = confusion_matrix(y_test, y_test_predict)\n",
    "print(matrixTest)\n",
    "print(\"Accuracy\", accuracy_score(y_test, y_test_predict))\n",
    "print(\"F1\", f1_score(y_test, y_test_predict, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM 5 fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "spliter = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "for train_indices, validate_indices in spliter.split(X, y):\n",
    "    SVM = SVC() #New model on each fold\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    SVM.fit(X_train,y_train)\n",
    "    X_validate = X.iloc[validate_indices]\n",
    "    y_validate = y.iloc[validate_indices]\n",
    "    y_predicted = SVM.predict(X_validate)\n",
    "    matrix = confusion_matrix(y_validate, y_predicted)\n",
    "    print(matrix)\n",
    "    print(\"Accuracy\", accuracy_score(y_validate,y_predicted))\n",
    "    print(\"F1\", f1_score(y_validate, y_predicted, average='weighted'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel = 'rbf')\n",
    "\n",
    "\n",
    "SVM.fit(X_train, y_train)\n",
    "y_train_predict = SVM.predict(X_train)\n",
    "matrixTrain = confusion_matrix(y_train, y_train_predict)\n",
    "print(matrixTrain)\n",
    "print(\"Accuracy\", accuracy_score(y_train, y_train_predict))\n",
    "print(\"F1\", f1_score(y_train ,y_train_predict, average='weighted'))\n",
    "\n",
    "y_test_predict = SVM.predict(X_test)\n",
    "matrixTest = confusion_matrix(y_test, y_test_predict)\n",
    "print(matrixTest)\n",
    "print(\"Accuracy\", accuracy_score(y_test, y_test_predict))\n",
    "print(\"F1\", f1_score(y_test, y_test_predict, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBF SVM 5 fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "spliter = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "for train_indices, validate_indices in spliter.split(X, y):\n",
    "    SVM = SVC(kernel='rbf') #New model on each fold\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    SVM.fit(X_train,y_train)\n",
    "    X_validate = X.iloc[validate_indices]\n",
    "    y_validate = y.iloc[validate_indices]\n",
    "    y_predicted = SVM.predict(X_validate)\n",
    "    matrix = confusion_matrix(y_validate, y_predicted)\n",
    "    print(matrix)\n",
    "    print(\"Accuracy\", accuracy_score(y_validate,y_predicted))\n",
    "    print(\"F1\", f1_score(y_validate, y_predicted, average='weighted'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poly SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel='poly')\n",
    "\n",
    "SVM.fit(X_train, y_train)\n",
    "y_train_predict = SVM.predict(X_train)\n",
    "matrixTrain = confusion_matrix(y_train, y_train_predict)\n",
    "print(matrixTrain)\n",
    "print(\"Accuracy\", accuracy_score(y_train, y_train_predict))\n",
    "print(\"F1\", f1_score(y_train ,y_train_predict, average='weighted'))\n",
    "\n",
    "\n",
    "y_test_predict = SVM.predict(X_test)\n",
    "matrixTest = confusion_matrix(y_test, y_test_predict)\n",
    "print(matrixTest)\n",
    "print(\"Accuracy\", accuracy_score(y_test, y_test_predict))\n",
    "print(\"F1\", f1_score(y_test, y_test_predict, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poly SVM 5 fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "spliter = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "for train_indices, validate_indices in spliter.split(X, y):\n",
    "    SVM = SVC(kernel='poly') #New model on each fold\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    SVM.fit(X_train,y_train)\n",
    "    X_validate = X.iloc[validate_indices]\n",
    "    y_validate = y.iloc[validate_indices]\n",
    "    y_predicted = SVM.predict(X_validate)\n",
    "    matrix = confusion_matrix(y_validate, y_predicted)\n",
    "    print(matrix)\n",
    "    print(\"Accuracy\", accuracy_score(y_validate,y_predicted))\n",
    "    print(\"F1\", f1_score(y_validate, y_predicted, average='weighted'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel='sigmoid')\n",
    "\n",
    "SVM.fit(X_train, y_train)\n",
    "y_train_predict = SVM.predict(X_train)\n",
    "matrixTrain = confusion_matrix(y_train, y_train_predict)\n",
    "print(matrixTrain)\n",
    "print(\"Accuracy\", accuracy_score(y_train, y_train_predict))\n",
    "print(\"F1\", f1_score(y_train ,y_train_predict, average='weighted'))\n",
    "\n",
    "y_test_predict = SVM.predict(X_test)\n",
    "matrixTest = confusion_matrix(y_test, y_test_predict)\n",
    "print(matrixTest)\n",
    "print(\"Accuracy\", accuracy_score(y_test, y_test_predict))\n",
    "print(\"F1\", f1_score(y_test, y_test_predict, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid SVM 5 fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "spliter = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "for train_indices, validate_indices in spliter.split(X, y):\n",
    "    SVM = SVC(kernel='sigmoid') #New model on each fold\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    SVM.fit(X_train,y_train)\n",
    "    X_validate = X.iloc[validate_indices]\n",
    "    y_validate = y.iloc[validate_indices]\n",
    "    y_predicted = SVM.predict(X_validate)\n",
    "    matrix = confusion_matrix(y_validate, y_predicted)\n",
    "    print(matrix)\n",
    "    print(\"Accuracy\", accuracy_score(y_validate,y_predicted))\n",
    "    print(\"F1\", f1_score(y_validate, y_predicted, average='weighted'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "SGD = SGDClassifier()\n",
    "\n",
    "SGD.fit(X_train, y_train)\n",
    "y_train_predict = SGD.predict(X_train)\n",
    "matrixTrain = confusion_matrix(y_train, y_train_predict)\n",
    "print(matrixTrain)\n",
    "print(\"Accuracy\", accuracy_score(y_train, y_train_predict))\n",
    "print(\"F1\", f1_score(y_train ,y_train_predict, average='weighted'))\n",
    "\n",
    "y_test_predict = SGD.predict(X_test)\n",
    "matrixTest = confusion_matrix(y_test, y_test_predict)\n",
    "print(matrixTest)\n",
    "print(\"Accuracy\", accuracy_score(y_test, y_test_predict))\n",
    "print(\"F1\", f1_score(y_test, y_test_predict, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent 5 fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "spliter = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "for train_indices, validate_indices in spliter.split(X, y):\n",
    "    SGD = SGDClassifier()\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    SGD.fit(X_train,y_train)\n",
    "    X_validate = X.iloc[validate_indices]\n",
    "    y_validate = y.iloc[validate_indices]\n",
    "    y_predicted = SGD.predict(X_validate)\n",
    "    matrix = confusion_matrix(y_validate, y_predicted)\n",
    "    print(matrix)\n",
    "    print(\"Accuracy\", accuracy_score(y_validate,y_predicted))\n",
    "    print(\"F1\", f1_score(y_validate, y_predicted, average='weighted'))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "RFC = RandomForestClassifier()\n",
    "\n",
    "\n",
    "RFC.fit(X_train, y_train)\n",
    "y_train_predict = RFC.predict(X_train)\n",
    "matrixTrain = confusion_matrix(y_train, y_train_predict)\n",
    "print(matrixTrain)\n",
    "print(\"Accuracy\", accuracy_score(y_train, y_train_predict))\n",
    "print(\"F1\", f1_score(y_train ,y_train_predict, average='weighted'))\n",
    "\n",
    "y_test_predict = RFC.predict(X_test)\n",
    "matrixTest = confusion_matrix(y_test, y_test_predict)\n",
    "print(matrixTest)\n",
    "print(\"Accuracy\", accuracy_score(y_test, y_test_predict))\n",
    "print(\"F1\", f1_score(y_test, y_test_predict, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest 5 fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "spliter = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "for train_indices, validate_indices in spliter.split(X, y):\n",
    "    RFC = RandomForestClassifier()\n",
    "    X_train = X.iloc[train_indices]\n",
    "    y_train = y.iloc[train_indices]\n",
    "    RFC.fit(X_train,y_train)\n",
    "    X_validate = X.iloc[validate_indices]\n",
    "    y_validate = y.iloc[validate_indices]\n",
    "    y_predicted = RFC.predict(X_validate)\n",
    "    matrix = confusion_matrix(y_validate, y_predicted)\n",
    "    print(matrix)\n",
    "    print(\"Accuracy\", accuracy_score(y_validate,y_predicted))\n",
    "    print(\"F1\", f1_score(y_validate, y_predicted, average='weighted'))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
